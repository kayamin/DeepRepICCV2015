{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import  matplotlib.pylab as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "b = Variable(torch.FloatTensor(10000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__add__',\n",
       " '__and__',\n",
       " '__bool__',\n",
       " '__class__',\n",
       " '__deepcopy__',\n",
       " '__delattr__',\n",
       " '__delitem__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__div__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__iadd__',\n",
       " '__iand__',\n",
       " '__idiv__',\n",
       " '__ilshift__',\n",
       " '__imul__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__invert__',\n",
       " '__ior__',\n",
       " '__ipow__',\n",
       " '__irshift__',\n",
       " '__isub__',\n",
       " '__iter__',\n",
       " '__itruediv__',\n",
       " '__ixor__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lshift__',\n",
       " '__lt__',\n",
       " '__matmul__',\n",
       " '__mod__',\n",
       " '__module__',\n",
       " '__mul__',\n",
       " '__ne__',\n",
       " '__neg__',\n",
       " '__new__',\n",
       " '__nonzero__',\n",
       " '__or__',\n",
       " '__pow__',\n",
       " '__radd__',\n",
       " '__rdiv__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__rmul__',\n",
       " '__rshift__',\n",
       " '__rsub__',\n",
       " '__rtruediv__',\n",
       " '__setattr__',\n",
       " '__setitem__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__sub__',\n",
       " '__subclasshook__',\n",
       " '__truediv__',\n",
       " '__weakref__',\n",
       " '__xor__',\n",
       " '_advanced_index_add',\n",
       " '_advanced_index_select',\n",
       " '_cdata',\n",
       " '_check_advanced_indexing',\n",
       " '_new_with_metadata_file',\n",
       " '_set_index',\n",
       " '_sparse_mask',\n",
       " '_torch',\n",
       " '_write_metadata',\n",
       " 'abs',\n",
       " 'abs_',\n",
       " 'acos',\n",
       " 'acos_',\n",
       " 'add',\n",
       " 'add_',\n",
       " 'addbmm',\n",
       " 'addbmm_',\n",
       " 'addcdiv',\n",
       " 'addcdiv_',\n",
       " 'addcmul',\n",
       " 'addcmul_',\n",
       " 'addmm',\n",
       " 'addmm_',\n",
       " 'addmv',\n",
       " 'addmv_',\n",
       " 'addr',\n",
       " 'addr_',\n",
       " 'apply_',\n",
       " 'asin',\n",
       " 'asin_',\n",
       " 'atan',\n",
       " 'atan2',\n",
       " 'atan2_',\n",
       " 'atan_',\n",
       " 'baddbmm',\n",
       " 'baddbmm_',\n",
       " 'bernoulli',\n",
       " 'bernoulli_',\n",
       " 'bmm',\n",
       " 'btrifact',\n",
       " 'btrisolve',\n",
       " 'byte',\n",
       " 'cauchy_',\n",
       " 'ceil',\n",
       " 'ceil_',\n",
       " 'char',\n",
       " 'chunk',\n",
       " 'clamp',\n",
       " 'clamp_',\n",
       " 'clone',\n",
       " 'contiguous',\n",
       " 'copy_',\n",
       " 'cos',\n",
       " 'cos_',\n",
       " 'cosh',\n",
       " 'cosh_',\n",
       " 'cpu',\n",
       " 'cross',\n",
       " 'cuda',\n",
       " 'cumprod',\n",
       " 'cumsum',\n",
       " 'data',\n",
       " 'data_ptr',\n",
       " 'diag',\n",
       " 'dim',\n",
       " 'dist',\n",
       " 'div',\n",
       " 'div_',\n",
       " 'dot',\n",
       " 'double',\n",
       " 'eig',\n",
       " 'element_size',\n",
       " 'eq',\n",
       " 'eq_',\n",
       " 'equal',\n",
       " 'exp',\n",
       " 'exp_',\n",
       " 'expand',\n",
       " 'expand_as',\n",
       " 'exponential_',\n",
       " 'fill_',\n",
       " 'float',\n",
       " 'floor',\n",
       " 'floor_',\n",
       " 'fmod',\n",
       " 'fmod_',\n",
       " 'frac',\n",
       " 'frac_',\n",
       " 'gather',\n",
       " 'ge',\n",
       " 'ge_',\n",
       " 'gels',\n",
       " 'geometric_',\n",
       " 'geqrf',\n",
       " 'ger',\n",
       " 'gesv',\n",
       " 'gt',\n",
       " 'gt_',\n",
       " 'half',\n",
       " 'histc',\n",
       " 'index',\n",
       " 'index_add_',\n",
       " 'index_copy_',\n",
       " 'index_fill_',\n",
       " 'index_select',\n",
       " 'int',\n",
       " 'inverse',\n",
       " 'is_contiguous',\n",
       " 'is_cuda',\n",
       " 'is_pinned',\n",
       " 'is_same_size',\n",
       " 'is_set_to',\n",
       " 'is_shared',\n",
       " 'is_signed',\n",
       " 'is_sparse',\n",
       " 'kthvalue',\n",
       " 'le',\n",
       " 'le_',\n",
       " 'lerp',\n",
       " 'lerp_',\n",
       " 'lgamma',\n",
       " 'lgamma_',\n",
       " 'log',\n",
       " 'log1p',\n",
       " 'log1p_',\n",
       " 'log_',\n",
       " 'log_normal_',\n",
       " 'long',\n",
       " 'lt',\n",
       " 'lt_',\n",
       " 'map2_',\n",
       " 'map_',\n",
       " 'masked_copy_',\n",
       " 'masked_fill_',\n",
       " 'masked_scatter_',\n",
       " 'masked_select',\n",
       " 'matmul',\n",
       " 'max',\n",
       " 'mean',\n",
       " 'median',\n",
       " 'min',\n",
       " 'mm',\n",
       " 'mode',\n",
       " 'mul',\n",
       " 'mul_',\n",
       " 'multinomial',\n",
       " 'mv',\n",
       " 'narrow',\n",
       " 'ndimension',\n",
       " 'ne',\n",
       " 'ne_',\n",
       " 'neg',\n",
       " 'neg_',\n",
       " 'nelement',\n",
       " 'new',\n",
       " 'nonzero',\n",
       " 'norm',\n",
       " 'normal_',\n",
       " 'numel',\n",
       " 'numpy',\n",
       " 'orgqr',\n",
       " 'ormqr',\n",
       " 'permute',\n",
       " 'pin_memory',\n",
       " 'potrf',\n",
       " 'potri',\n",
       " 'potrs',\n",
       " 'pow',\n",
       " 'pow_',\n",
       " 'prod',\n",
       " 'pstrf',\n",
       " 'qr',\n",
       " 'random_',\n",
       " 'reciprocal',\n",
       " 'reciprocal_',\n",
       " 'remainder',\n",
       " 'remainder_',\n",
       " 'renorm',\n",
       " 'renorm_',\n",
       " 'repeat',\n",
       " 'resize_',\n",
       " 'resize_as_',\n",
       " 'round',\n",
       " 'round_',\n",
       " 'rsqrt',\n",
       " 'rsqrt_',\n",
       " 'scatter_',\n",
       " 'scatter_add_',\n",
       " 'select',\n",
       " 'set_',\n",
       " 'shape',\n",
       " 'share_memory_',\n",
       " 'short',\n",
       " 'sigmoid',\n",
       " 'sigmoid_',\n",
       " 'sign',\n",
       " 'sign_',\n",
       " 'sin',\n",
       " 'sin_',\n",
       " 'sinh',\n",
       " 'sinh_',\n",
       " 'size',\n",
       " 'sort',\n",
       " 'split',\n",
       " 'sqrt',\n",
       " 'sqrt_',\n",
       " 'squeeze',\n",
       " 'squeeze_',\n",
       " 'std',\n",
       " 'storage',\n",
       " 'storage_offset',\n",
       " 'storage_type',\n",
       " 'stride',\n",
       " 'sub',\n",
       " 'sub_',\n",
       " 'sum',\n",
       " 'svd',\n",
       " 'symeig',\n",
       " 't',\n",
       " 't_',\n",
       " 'tan',\n",
       " 'tan_',\n",
       " 'tanh',\n",
       " 'tanh_',\n",
       " 'tolist',\n",
       " 'topk',\n",
       " 'trace',\n",
       " 'transpose',\n",
       " 'transpose_',\n",
       " 'tril',\n",
       " 'tril_',\n",
       " 'triu',\n",
       " 'triu_',\n",
       " 'trtrs',\n",
       " 'trunc',\n",
       " 'trunc_',\n",
       " 'type',\n",
       " 'type_as',\n",
       " 'unfold',\n",
       " 'uniform_',\n",
       " 'unsqueeze',\n",
       " 'unsqueeze_',\n",
       " 'var',\n",
       " 'view',\n",
       " 'view_as',\n",
       " 'zero_']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(b.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 9291.6963\n",
       " 6038.0786\n",
       " 9407.4697\n",
       "    ⋮     \n",
       " 8109.0034\n",
       " 1029.3820\n",
       " 9543.2783\n",
       "[torch.FloatTensor of size 10000]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.data.uniform_(0, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  7.,  12.,  13.,   5.,  10.,  10.,   8.,  15.,   9.,  15.,  15.,\n",
       "          7.,   4.,   7.,   8.,   8.,   3.,  11.,   9.,   8.,  13.,   7.,\n",
       "          8.,  11.,  13.,   7.,   7.,   9.,  12.,  11.,  12.,   8.,  12.,\n",
       "          6.,   7.,  14.,   3.,  11.,   8.,   7.,  12.,   6.,   9.,  12.,\n",
       "          7.,  11.,   9.,   5.,   8.,  11.,   7.,  11.,  11.,  14.,  14.,\n",
       "         12.,  11.,   9.,   9.,   8.,  10.,  12.,  14.,  12.,   9.,   9.,\n",
       "          8.,   9.,  14.,  10.,  15.,   9.,  11.,   8.,  14.,  10.,  17.,\n",
       "         17.,   5.,   8.,  10.,   6.,   4.,  16.,  14.,   9.,  10.,   4.,\n",
       "          9.,  10.,   3.,   8.,  15.,  11.,  11.,   7.,   8.,   7.,   5.,\n",
       "          9.,   8.,   5.,   9.,   9.,   3.,   8.,   7.,  15.,   9.,   7.,\n",
       "          3.,  12.,  11.,  13.,   8.,  13.,  10.,   8.,   9.,   8.,   4.,\n",
       "          4.,  14.,  18.,  10.,   5.,   7.,  10.,  16.,   9.,  11.,  11.,\n",
       "          6.,   6.,  14.,   9.,  15.,  10.,  12.,  11.,   6.,   3.,   7.,\n",
       "          7.,   6.,  17.,  11.,   6.,   7.,  10.,  11.,  10.,  15.,  10.,\n",
       "          5.,  10.,   6.,   9.,  16.,   9.,   8.,   7.,   5.,  10.,  14.,\n",
       "          9.,  14.,  14.,   7.,   7.,  12.,  11.,  12.,  13.,   8.,  14.,\n",
       "          7.,  13.,   7.,   9.,   7.,   6.,  11.,  12.,   8.,   8.,  18.,\n",
       "         16.,  13.,   9.,   9.,  12.,  12.,   9.,   6.,   7.,   9.,  10.,\n",
       "          6.,   5.,  12.,  14.,   4.,  10.,   5.,  12.,  12.,   6.,  10.,\n",
       "         11.,  10.,   7.,  10.,   9.,   8.,  10.,   9.,  16.,  10.,  15.,\n",
       "         13.,  15.,   4.,   7.,   9.,  10.,  11.,   6.,   8.,   8.,  10.,\n",
       "         10.,  11.,   9.,  10.,   5.,   8.,  14.,  10.,  16.,  14.,   7.,\n",
       "         10.,  11.,  12.,   8.,   7.,  10.,   7.,   7.,   8.,  22.,   7.,\n",
       "          9.,  12.,  14.,   8.,  13.,  10.,  13.,   7.,  11.,  13.,  13.,\n",
       "          7.,  12.,  10.,   7.,  11.,  13.,  10.,   8.,  13.,   8.,  14.,\n",
       "         15.,  14.,   9.,   8.,  11.,  11.,  13.,   8.,  12.,  10.,   3.,\n",
       "          5.,   6.,  11.,  15.,  17.,  12.,  12.,   9.,   7.,  14.,   7.,\n",
       "          7.,   8.,   6.,  11.,   8.,  10.,  11.,  18.,   8.,  10.,  14.,\n",
       "         11.,   9.,  13.,   6.,   8.,  14.,  11.,   8.,   7.,  13.,  12.,\n",
       "         11.,  11.,   8.,   7.,   6.,   5.,  14.,   6.,   9.,   8.,  11.,\n",
       "          8.,  14.,  12.,  13.,   8.,   3.,  15.,  12.,   7.,  10.,  10.,\n",
       "         14.,   8.,  14.,  12.,  12.,  12.,   6.,   6.,   6.,   8.,   8.,\n",
       "          8.,  11.,   9.,  10.,   9.,   6.,  10.,  12.,   8.,  10.,   6.,\n",
       "         12.,  19.,   9.,  13.,   5.,  11.,   8.,  12.,  15.,   8.,  15.,\n",
       "         11.,  19.,  11.,   5.,  14.,  10.,  11.,   9.,  12.,   6.,  15.,\n",
       "          5.,  12.,  12.,  14.,   8.,   8.,   2.,  11.,  16.,  10.,   8.,\n",
       "          8.,  13.,   8.,   5.,  17.,  16.,   9.,   8.,  12.,   7.,  11.,\n",
       "         11.,   6.,   7.,  10.,   9.,  11.,  13.,  10.,  17.,   8.,   4.,\n",
       "          8.,   7.,   6.,  12.,  10.,   8.,  10.,   8.,  16.,   5.,   6.,\n",
       "          8.,   6.,   9.,   8.,   6.,  10.,  13.,  17.,  11.,   7.,   9.,\n",
       "          6.,  16.,  14.,   7.,  10.,   9.,  19.,  10.,  14.,   8.,   8.,\n",
       "         16.,   7.,  11.,   6.,  11.,  10.,   5.,   9.,  14.,   8.,  12.,\n",
       "         10.,   7.,   4.,  13.,  12.,   8.,  12.,   7.,   9.,  10.,  11.,\n",
       "         12.,   9.,  12.,   5.,   3.,  11.,  13.,  10.,  11.,  12.,  15.,\n",
       "          8.,  10.,   5.,  12.,  13.,  11.,  10.,  11.,  11.,   9.,   9.,\n",
       "          5.,  11.,  17.,   6.,  13.,  11.,   8.,  11.,   9.,  11.,  12.,\n",
       "         15.,  11.,  16.,  10.,  13.,  14.,  11.,   7.,   9.,   5.,  16.,\n",
       "          7.,   9.,   6.,   7.,  11.,  12.,   9.,  10.,  14.,   8.,  13.,\n",
       "          7.,  15.,  10.,  10.,  14.,   9.,   8.,   5.,  11.,   8.,   6.,\n",
       "         11.,   5.,  13.,  11.,  12.,  11.,   9.,  13.,   5.,   5.,   8.,\n",
       "          7.,  12.,   6.,  13.,   7.,   3.,   5.,  13.,  19.,   8.,  11.,\n",
       "         11.,   5.,  11.,  10.,   9.,   6.,  17.,   8.,  10.,  11.,   6.,\n",
       "          9.,  15.,   9.,   8.,  11.,  10.,  12.,   7.,  11.,  14.,  10.,\n",
       "         12.,  12.,  14.,  11.,   8.,   9.,  12.,   7.,  11.,   9.,  16.,\n",
       "          8.,  14.,   8.,   8.,   8.,   5.,   9.,  12.,   4.,  11.,  12.,\n",
       "          8.,  11.,   9.,  10.,  15.,  10.,   5.,  13.,   8.,   9.,   8.,\n",
       "         11.,  18.,  10.,  12.,  10.,  13.,   7.,  14.,   8.,  11.,  12.,\n",
       "         12.,   8.,   9.,   6.,   9.,  13.,   9.,   9.,  16.,  16.,  14.,\n",
       "         12.,   9.,  11.,  11.,   5.,   8.,  14.,   8.,  16.,   9.,  15.,\n",
       "          8.,   9.,  15.,   7.,  10.,  11.,  16.,   8.,  13.,  14.,  14.,\n",
       "          9.,   7.,   8.,  14.,   5.,   6.,  10.,   6.,  12.,  10.,  10.,\n",
       "          9.,  13.,   9.,  14.,   8.,  11.,   7.,  12.,   8.,   9.,  14.,\n",
       "         12.,  12.,  12.,  14.,   4.,   6.,  15.,  10.,   9.,  11.,   9.,\n",
       "         11.,  10.,  13.,   8.,   8.,  12.,   4.,  10.,  11.,  13.,  13.,\n",
       "         11.,   4.,   5.,  13.,  10.,   6.,  10.,   6.,  11.,   8.,  16.,\n",
       "          6.,  10.,   9.,  16.,  13.,   8.,  13.,   9.,   6.,   5.,  13.,\n",
       "         12.,   9.,   7.,  10.,  15.,  10.,  17.,   5.,   9.,  16.,   8.,\n",
       "          9.,  15.,   8.,  18.,  12.,  12.,  13.,  10.,  10.,   9.,  10.,\n",
       "          9.,  10.,   6.,  10.,  14.,   8.,  11.,  13.,  11.,   9.,  10.,\n",
       "          5.,  10.,  22.,  10.,  14.,  15.,   8.,   7.,   4.,  15.,  13.,\n",
       "          6.,   7.,  11.,   6.,   8.,  10.,  12.,  11.,  11.,   7.,   9.,\n",
       "         10.,   9.,  18.,   8.,   9.,  10.,   8.,  10.,   8.,   8.,   8.,\n",
       "          6.,  16.,  15.,  14.,   9.,  10.,   8.,   9.,  13.,  10.,  10.,\n",
       "          3.,   9.,  13.,  10.,  10.,   9.,   9.,  12.,   9.,  12.,  10.,\n",
       "         14.,  10.,   7.,  13.,  12.,   9.,   8.,   4.,   8.,   5.,  13.,\n",
       "          8.,  10.,   9.,   8.,  10.,   5.,  10.,   6.,   8.,   9.,  12.,\n",
       "          9.,  19.,  12.,  13.,   6.,   9.,  13.,   9.,   9.,  12.,   5.,\n",
       "         14.,  10.,  11.,  19.,  11.,  12.,  12.,  15.,   9.,  22.,   6.,\n",
       "          5.,   9.,  11.,   7.,  10.,   2.,  11.,   9.,  18.,   5.,   9.,\n",
       "         13.,   8.,   8.,   7.,  14.,  10.,   9.,  10.,  10.,   8.,  13.,\n",
       "          8.,   8.,   9.,   6.,  11.,  12.,  12.,  14.,   9.,   7.,   8.,\n",
       "          9.,  12.,   9.,  11.,  16.,   8.,   8.,   5.,   9.,  14.,  16.,\n",
       "         12.,   6.,   9.,   8.,  11.,  11.,  12.,  10.,  12.,   9.,  11.,\n",
       "          6.,   9.,   8.,   8.,  15.,  10.,  13.,  11.,  14.,  10.,   4.,\n",
       "         11.,  14.,  15.,  12.,   7.,   7.,  10.,   9.,  10.,  12.,   6.,\n",
       "          7.,  13.,   7.,  11.,  15.,  11.,   9.,   7.,  15.,   9.,  16.,\n",
       "          7.,   8.,   6.,   4.,  11.,  15.,  10.,   8.,  14.,   5.,  10.,\n",
       "          9.,  11.,   9.,   8.,   7.,  11.,  10.,  12.,  10.,  11.,  13.,\n",
       "         10.,  16.,  15.,  10.,  10.,  13.,   7.,  12.,   8.,   9.,  15.,\n",
       "          8.,  15.,  11.,  10.,  14.,  11.,  10.,   9.,  16.,   5.,  16.,\n",
       "          5.,  12.,  15.,   8.,  11.,   8.,   9.,  10.,   6.,   5.]),\n",
       " array([  1.51614666e-01,   1.01510627e+01,   2.01505107e+01, ...,\n",
       "          9.97960071e+03,   9.98960016e+03,   9.99959961e+03]),\n",
       " <a list of 1000 Patch objects>)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nINABIAkCHQCSINABIIkfA3F2RGN4e4syAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e0cfc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(b.data.numpy(), 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.04319239,  1.03169596,  1.05311501, ...,  0.99532932,\n",
       "        0.98236912,  1.08803213], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b.data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import pdb\n",
    "\n",
    "# 畳み込み -> MaxPooling -> ReLU を行うクラス\n",
    "# Live Repetition Counting ネットワーク\n",
    "\n",
    "class RepetitionCountingNet(nn.Module):\n",
    "\n",
    "    def __init__(self, parameter_path=None):\n",
    "        super(RepetitionCountingNet, self).__init__()\n",
    "\n",
    "        # takes input as Batch x Frames(channel) x Height x Width form\n",
    "        convLayers = [\n",
    "\n",
    "        nn.Conv2d(20, 40, 5, 1, bias=False),     # Bx20x50x50 -> Bx40x46x46\n",
    "        nn.MaxPool2d(2),                        # Bx40x46x46 -> Bx40x23x23\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(40, 60, 3, 1, bias=False),     # Bx40x23x23 -> Bx60x21x21\n",
    "        nn.MaxPool2d(2),                        # Bx60x21x21 -> Bx60x10x10\n",
    "        nn.ReLU(),\n",
    "        nn.Conv2d(60, 90, 3, 1, bias=False),     # Bx60x10x10 -> Bx90x8x8\n",
    "        nn.MaxPool2d(2),                        # Bx90x8x8   -> Bx90x4x4\n",
    "        nn.ReLU(),\n",
    "\n",
    "        ]\n",
    "\n",
    "        fcLayers = [\n",
    "\n",
    "        nn.Linear(4*4*90, 500, bias=True),  # Bx(4*4*90) -> Bx500\n",
    "        nn.Linear(500, 8, bias=True)        # Bx500 -> Bx8\n",
    "\n",
    "        ]\n",
    "\n",
    "        self.convLayers = nn.Sequential(*convLayers)\n",
    "        self.fcLayers = nn.Sequential(*fcLayers)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        x = self.convLayers(input)\n",
    "        x = x.view(-1, 4*4*90)\n",
    "        x = self.fcLayers(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = RepetitionCountingNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-17-3033d9f6d6c3>(1)<module>()\n",
      "-> for i, m in enumerate(test.modules()):\n",
      "(Pdb) m\n",
      "RepetitionCountingNet (\n",
      "  (convLayers): Sequential (\n",
      "    (0): Conv2d(20, 40, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "    (1): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    (2): ReLU ()\n",
      "    (3): Conv2d(40, 60, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (4): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    (5): ReLU ()\n",
      "    (6): Conv2d(60, 90, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "    (7): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "    (8): ReLU ()\n",
      "  )\n",
      "  (fcLayers): Sequential (\n",
      "    (0): Linear (1440 -> 500)\n",
      "    (1): Linear (500 -> 8)\n",
      "  )\n",
      ")\n",
      "(Pdb) c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-17-3033d9f6d6c3>(1)<module>()\n",
      "-> for i, m in enumerate(test.modules()):\n",
      "(Pdb) m\n",
      "Sequential (\n",
      "  (0): Conv2d(20, 40, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "  (1): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (2): ReLU ()\n",
      "  (3): Conv2d(40, 60, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (4): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (5): ReLU ()\n",
      "  (6): Conv2d(60, 90, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
      "  (7): MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "  (8): ReLU ()\n",
      ")\n",
      "(Pdb) c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-17-3033d9f6d6c3>(1)<module>()\n",
      "-> for i, m in enumerate(test.modules()):\n",
      "(Pdb) m\n",
      "Conv2d(20, 40, kernel_size=(5, 5), stride=(1, 1), bias=False)\n",
      "(Pdb) c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-17-3033d9f6d6c3>(1)<module>()\n",
      "-> for i, m in enumerate(test.modules()):\n",
      "(Pdb) c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-17-3033d9f6d6c3>(1)<module>()\n",
      "-> for i, m in enumerate(test.modules()):\n",
      "(Pdb) c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-17-3033d9f6d6c3>(1)<module>()\n",
      "-> for i, m in enumerate(test.modules()):\n",
      "(Pdb) c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-17-3033d9f6d6c3>(1)<module>()\n",
      "-> for i, m in enumerate(test.modules()):\n",
      "(Pdb) c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-17-3033d9f6d6c3>(1)<module>()\n",
      "-> for i, m in enumerate(test.modules()):\n",
      "(Pdb) c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-17-3033d9f6d6c3>(1)<module>()\n",
      "-> for i, m in enumerate(test.modules()):\n",
      "(Pdb) c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-17-3033d9f6d6c3>(1)<module>()\n",
      "-> for i, m in enumerate(test.modules()):\n",
      "(Pdb) m\n",
      "MaxPool2d (size=(2, 2), stride=(2, 2), dilation=(1, 1))\n",
      "(Pdb) c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-17-3033d9f6d6c3>(1)<module>()\n",
      "-> for i, m in enumerate(test.modules()):\n",
      "(Pdb) m\n",
      "ReLU ()\n",
      "(Pdb) c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-17-3033d9f6d6c3>(1)<module>()\n",
      "-> for i, m in enumerate(test.modules()):\n",
      "(Pdb) m\n",
      "Sequential (\n",
      "  (0): Linear (1440 -> 500)\n",
      "  (1): Linear (500 -> 8)\n",
      ")\n",
      "(Pdb) c\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-17-3033d9f6d6c3>(1)<module>()\n",
      "-> for i, m in enumerate(test.modules()):\n",
      "(Pdb) m\n",
      "Linear (1440 -> 500)\n",
      "(Pdb) m.weight.size()\n",
      "torch.Size([500, 1440])\n"
     ]
    }
   ],
   "source": [
    "for i, m in enumerate(test.modules()):\n",
    "    display(i)\n",
    "    pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "wt = np.zeros([40, 20 , 5, 5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--Return--\n",
      "> <ipython-input-34-7fec4988e48c>(2)<module>()->None\n",
      "-> pdb.set_trace()\n",
      "(Pdb) type(l2_reg)\n",
      "<class 'NoneType'>\n",
      "(Pdb) c\n"
     ]
    }
   ],
   "source": [
    "l2_reg = None\n",
    "pdb.set_trace()\n",
    "for W in test.parameters():\n",
    "    if l2_reg is None:\n",
    "        l2_reg = W.norm(2)\n",
    "    else:\n",
    "        l2_reg = l2_reg + W.norm(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-37-938081d27240>(1)<module>()->None\n",
      "-> for W in test.parameters():\n",
      "(Pdb) W.norm(1)\n",
      "Variable containing:\n",
      " 448.9650\n",
      "[torch.FloatTensor of size 1]\n",
      "\n",
      "(Pdb) q\n"
     ]
    },
    {
     "ename": "BdbQuit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBdbQuit\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-938081d27240>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mW\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-37-938081d27240>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mW\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mpdb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_trace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mtrace_dispatch\u001b[0;34m(self, frame, event, arg)\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;31m# None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'line'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'call'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.pyenv/versions/3.6.1/lib/python3.6/bdb.py\u001b[0m in \u001b[0;36mdispatch_line\u001b[0;34m(self, frame)\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbreak_here\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mquitting\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mBdbQuit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrace_dispatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mBdbQuit\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for W in test.parameters():\n",
    "    pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       " 0\n",
       "[torch.FloatTensor of size 1]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Variable(torch.FloatTensor(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.3333333333333333"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean([1,1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = [3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = Variable(torch.FloatTensor(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "a = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if a:\n",
    "    print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
